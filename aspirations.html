<!DOCTYPE html>
<html>
  <head>
    <title>Jim | Aspirations</title>
    <link rel="stylesheet" href="assets/css/normalize.css">
    <link rel="stylesheet" href="assets/css/style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Funnel+Display:wght@300..800&display=swap" rel="stylesheet">
  </head>
  <body>
	<nav>
	  <ul>
        <li><a href="index.html">Main Page</a></li>
		<li><a href="projects.html">Projects</a></li>
		<li><a href="notes.html">Notes</a></li>
        <li><a href="hobbies.html">Hobbies</a></li>
        <li><a href="aspirations.html">Aspirations</a></li>
	  </ul>
	</nav>

    <header>
      <h1>Aspirations and Philosophy</h1>
    </header>

    <section>
      <div class="sectitle">
        <h2>Goals</h2>
      </div>
      <p>
        I'm currently in first year, but I'm looking forward to specializing in AI or formal
        methods. At the moment, statistical learning and mathematical logic are, naturally my main
        subjects of extracurricular study.
      </p>
      <p>
        While you can look at <a href="projects.html">my projects</a> to see what I'm currently
        experimenting with (currently mostly whimsical thoughts I have), currently most of my
        more ambitious ideas have been left on the backburne, among which are a cluster made from
        80s 8-bit microprocessors, a classical AI spell-checked and grammar analyzer, and a
        classical AI system for document segmentation and markdown extraction from pdf.
      </p>
    </section>

    <section>
      <div class="sectitle">
        <h2>Getting Work Done</h2>
      </div>
      <p>
        Especially since taking AP courses, there has been a lot of focus from my peers on
        optimizing studying and grinding out as much work as possible, whether it be personal
        projects, extracurriculars, or academics.
      </p>
      <p>
        I'd certainly be lying if I said that I don't fall into this trap myself. When you sit down
        and get into a problem set or a cool programming project or learn about some new idea, it's
        easy to get so caught up in what you're doing that you forget to take care of yourself. And
        when it's not, it's easy to blame yourself and to make plans to maximize productivity for
        the remainder of the day.
      </p>
      <p>
        While I think that certainly an emphasis on efficiency is good and it drives you to produce
        better work and to hone your skills, it can also be quite toxic when you inevitably at some
        point fail to meet your expectations and beat yourself up when reasonably, you can't
        <emph>really</emph> have been expected to spend 10 completely focused hours on linear
        algebra.
      </p>
      <p>
        While it might sound whimsical and sweet and completely ignorable, taking care of yourself
        is probably one of your top priorities. If you need a reason, it's because you won't be
        able to cherish the fruits of your success and all if you're dead at age 19 of stress and
        cardiovascular disease. If that doesn't convince you, taking a break and letting your
        brain subconsciously toss around the concepts you've been grinding at can be just what you
        need. Case in point: Albert Einstein conceived some of his most revolutionary ideas being
        bored as a clerk, not grinding away at his studies. So overall, I think that
        <emph>attention</emph> to your productivity is important, but living life is, too.
      </p>
    </section>

    <section>
      <div class="sectitle">
        <h2>On AI</h2>
      </div>
      <section>
        <h3>Using LLMs</h3>
        <p>
          Lately, most people around me have been using LLMs. Where I study, it's almost the norm
          at this point&mdash;if you can't solve a problem, you ask AI. If the AI can't solve it,
          you ask another AI. For perhaps less educational purposes, it seems that a lot of people
          also use it to hack together personal projects and to get away with doing less in group
          projects. To be fair, I think this totally works for most of my peers since
          (most of them) still do emphasize <emph>not</emph> just blindly following AI where it
          matters most.
        </p>
        <p>
          I've made the conscious choice to avoid AI, at least for now. I recognize the potential
          it already has for streamlining workflows and pruning out repetitive, well-defined tasks,
          but I want to avoid becoming increasingly dependent anytime I don't want to do something
          properly. I feel that especially at my stage of learning, going through and solving
          problems, no matter how repetitive, manually helps build valuable intuition. Thus, until
          circumstances change, I have decided to stick to reading documentation and building
          basic skills.
        </p>
      </section>

      <section>
        <h3>Trusting AI</h3>
        <p>
          I think that Neural Networks are an impressive technology, and it's hard to cast doubt on
          the fact that they've achieved some very impressive results already with LLMs, image
          generation, and a number of other fields where the data is too unstructured or ambiguous
          for traditional algorithms to analyze. I think that the technology right now could be
          overhyped, but it doesn't take away from the sheer brilliance of the technology.
        </p>
        <p>
          Nevertheless, I prefer not to trust AI. Although LLMs have gotten shockingly accurate in
          the last year or so (the free GPT offering has been outdoing most of my class in
          Calculus), they're still known to fail, especially when doing long, drawn-out numerical
          computations. This unfortunate tendency, combined with the fact that it's difficult to
          verify the logical and factual "correctness" of an answer (the chain of thought reasoning
          helps here but is imperfect), make using AI a slight gamble.
        </p>
        <p>
          This limitation of current LLMs is part of the reason why I'd like to continue studying
          formal logic! While classical AI is certainly not nearly as capable as a GPT in many
          tasks, it also provides strictly logical and traceable reasoning for its conclusions.
          Besides, I think it would be really cool to have a mostly complete theoretical
          understanding of the mathematical properties of an AI algorithm.
        </p>
      </section>
    </section>
  </body>
</html>
